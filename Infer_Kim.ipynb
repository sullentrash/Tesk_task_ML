{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Infer_Kim.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-ah8YDSgUJB",
        "outputId": "ed42ac56-af99-4482-fc81-b1e210550de2"
      },
      "source": [
        "!pip install timm\n",
        "import os\n",
        "import torch\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import timm as tm\n",
        "from PIL import Image\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "%matplotlib inline"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting timm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/89/d94f59780b5dd973154bf506d8ce598f6bfe7cc44dd445d644d6d3be8c39/timm-0.4.5-py3-none-any.whl (287kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 20.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20kB 15.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 30kB 13.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 51kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 61kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 71kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 81kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 92kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 102kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 112kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 122kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 133kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 143kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 153kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 163kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 174kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 184kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 194kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 204kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 215kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 225kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 235kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 245kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 256kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 266kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 276kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 286kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.9.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0bZt5PShT77",
        "outputId": "0cb6dd78-6bc4-42de-d116-31ec4f1b40a7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_dnj8DVhnQs"
      },
      "source": [
        "with zipfile.ZipFile('/content/drive/MyDrive/test1.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('/content')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RuSBE41jP2-",
        "outputId": "c02500af-a9bd-4e8e-b46c-8e1726b077cd"
      },
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suTKH-34gde_"
      },
      "source": [
        "path_to_model - Путь до модели\n",
        "\n",
        "path_to_images - Путь до папки с изображениями"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpEalpKtgakv"
      },
      "source": [
        "\n",
        "def infer(path_to_model, path_to_images):\n",
        "    model = tm.create_model('efficientnet_b3a', pretrained=True, num_classes=22)\n",
        "    model = to_device(model, device)\n",
        "    model_s = torch.load(path_to_model)\n",
        "    model.load(model_s)\n",
        "    model.eval()\n",
        "\n",
        "    pil2tensor = transforms.ToTensor()\n",
        "    images = []\n",
        "    predictions = []\n",
        "    index = []\n",
        "    i = 0\n",
        "    for filename in os.listdir(path_to_images):\n",
        "        img = Image.open(path_to_images + '/' + filename)\n",
        "        xb = img \n",
        "        xb =  xb.resize((224, 224))\n",
        "        xb = pil2tensor(xb)\n",
        "        xb = to_device(xb, device)\n",
        "        preds = model(xb.reshape(1, 3, 224, 224))\n",
        "        prediction = preds[0]\n",
        "        _, preds = torch.max(prediction, dim=0)\n",
        "        preds.cpu()\n",
        "        label = labels[preds.item()]\n",
        "        images.append(filename)\n",
        "        index.append( int(filename.split('.')[0]) )\n",
        "        predictions.append(label)\n",
        "    output = pd.DataFrame(data={\"index\":index,\"image\":images,\"label\":predictions})\n",
        "    sorted_df = output.sort_values(by=[\"index\"], ascending=True) \n",
        "    sorted_df = sorted_df.drop(columns=\"index\")\n",
        "    sorted_df.to_csv(path_or_buf=\"submission.csv\", index=False, quoting=3)\n",
        "\n",
        "infer('/content/E_Net_84.pt', '/content/test1')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "IfZmaIirnj4g",
        "outputId": "9115532f-995f-430c-be2f-cf0dc59f8389"
      },
      "source": [
        "def infer(path_to_model, path_to_images): \n",
        "  model = tm.create_model('efficientnet_b3a', pretrained=True, num_classes=22) \n",
        "  model = to_device(model, device) \n",
        "  model_s = torch.load(path_to_model) \n",
        "  model.load_state_dict(model_s) \n",
        "  model.eval()\n",
        "\n",
        "  pil2tensor = transforms.ToTensor()\n",
        "  images = []\n",
        "  predictions = []\n",
        "  index = []\n",
        "  i = 0\n",
        "  for filename in os.listdir(path_to_images):\n",
        "    img = Image.open(path_to_images + '/' + filename)\n",
        "    xb = img \n",
        "    xb =  xb.resize((224, 224))\n",
        "    xb = pil2tensor(xb)\n",
        "    xb = to_device(xb, device)\n",
        "    preds = model(xb.reshape(1, 3, 224, 224))\n",
        "    prediction = preds[0]\n",
        "    _, preds = torch.max(prediction, dim=0)\n",
        "    preds.cpu()\n",
        "    label = labels[preds.item()]\n",
        "    images.append(filename)\n",
        "    index.append( int(filename.split('.')[0]) )\n",
        "    predictions.append(label)\n",
        "  output = pd.DataFrame(data={\"index\":index,\"image\":images,\"label\":predictions})\n",
        "  sorted_df = output.sort_values(by=[\"index\"], ascending=True) \n",
        "  sorted_df = sorted_df.drop(columns=\"index\")\n",
        "  sorted_df.to_csv(path_or_buf=\"submission.csv\", index=False, quoting=3)\n",
        "\n",
        "infer('/content/E_Net_84.pt', '/content/test1')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-4e1c27fcbd2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0msorted_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"submission.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/E_Net_84.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/test1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-4e1c27fcbd2b>\u001b[0m in \u001b[0;36minfer\u001b[0;34m(path_to_model, path_to_images)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mmodel_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1224\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for EfficientNet:\n\tMissing key(s) in state_dict: \"conv_stem.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"blocks.0.0.conv_dw.weight\", \"blocks.0.0.bn1.weight\", \"blocks.0.0.bn1.bias\", \"blocks.0.0.bn1.running_mean\", \"blocks.0.0.bn1.running_var\", \"blocks.0.0.se.conv_reduce.weight\", \"blocks.0.0.se.conv_reduce.bias\", \"blocks.0.0.se.conv_expand.weight\", \"blocks.0.0.se.conv_expand.bias\", \"blocks.0.0.conv_pw.weight\", \"blocks.0.0.bn2.weight\", \"blocks.0.0.bn2.bias\", \"blocks.0.0.bn2.running_mean\", \"blocks.0.0.bn2.running_var\", \"blocks.0.1.conv_dw.weight\", \"blocks.0.1.bn1.weight\", \"blocks.0.1.bn1.bias\", \"blocks.0.1.bn1.running_mean\", \"blocks.0.1.bn1.running_var\", \"blocks.0.1.se.conv_reduce.weight\", \"blocks.0.1.se.conv_reduce.bias\", \"blocks.0.1.se.conv_expand.weight\", \"blocks.0.1.se.conv_expand.bias\", \"blocks.0.1.conv_pw.weight\", \"blocks.0.1.bn2.weight\", \"blocks.0.1.bn2.bias\", \"blocks.0.1.bn2.running_mean\", \"blocks.0.1.bn2.running_var\", \"blocks.1.0.conv_pw.weight\", \"blocks.1.0.bn1.weight\", \"blocks.1.0.bn1.bias\", \"blocks.1.0.bn1.running_mean\", \"blocks.1.0.bn1.running_var\", \"blocks.1.0.conv_dw.weight\", \"blocks.1.0.bn2.weight\", \"blocks.1.0.bn2.bias\", \"blocks.1.0.bn2.running_mean\", \"blocks.1.0.bn2.running_var\", \"blocks.1.0.se.conv_reduce.weight\", \"blocks.1.0.se.conv_reduce.bias\", \"blocks.1.0.se.conv_expand.weight\", \"blocks.1.0.se.conv_expand.bias\", \"blocks.1.0.conv_pwl.weight\", \"blocks.1.0.bn3.weight\", \"blocks.1.0.bn3.bias\", \"blocks.1.0.bn3.running_mean\", \"blocks.1.0.bn3.running_...\n\tUnexpected key(s) in state_dict: \"network.conv_stem.weight\", \"network.bn1.weight\", \"network.bn1.bias\", \"network.bn1.running_mean\", \"network.bn1.running_var\", \"network.bn1.num_batches_tracked\", \"network.blocks.0.0.conv_dw.weight\", \"network.blocks.0.0.bn1.weight\", \"network.blocks.0.0.bn1.bias\", \"network.blocks.0.0.bn1.running_mean\", \"network.blocks.0.0.bn1.running_var\", \"network.blocks.0.0.bn1.num_batches_tracked\", \"network.blocks.0.0.se.conv_reduce.weight\", \"network.blocks.0.0.se.conv_reduce.bias\", \"network.blocks.0.0.se.conv_expand.weight\", \"network.blocks.0.0.se.conv_expand.bias\", \"network.blocks.0.0.conv_pw.weight\", \"network.blocks.0.0.bn2.weight\", \"network.blocks.0.0.bn2.bias\", \"network.blocks.0.0.bn2.running_mean\", \"network.blocks.0.0.bn2.running_var\", \"network.blocks.0.0.bn2.num_batches_tracked\", \"network.blocks.0.1.conv_dw.weight\", \"network.blocks.0.1.bn1.weight\", \"network.blocks.0.1.bn1.bias\", \"network.blocks.0.1.bn1.running_mean\", \"network.blocks.0.1.bn1.running_var\", \"network.blocks.0.1.bn1.num_batches_tracked\", \"network.blocks.0.1.se.conv_reduce.weight\", \"network.blocks.0.1.se.conv_reduce.bias\", \"network.blocks.0.1.se.conv_expand.weight\", \"network.blocks.0.1.se.conv_expand.bias\", \"network.blocks.0.1.conv_pw.weight\", \"network.blocks.0.1.bn2.weight\", \"network.blocks.0.1.bn2.bias\", \"network.blocks.0.1.bn2.running_mean\", \"network.blocks.0.1.bn2.running_var\", \"network.blocks.0.1.bn2.num_batches_tracked\", \"network.blocks.1.0.conv_pw.weight\", \"network.blocks.1.0.bn1.we..."
          ]
        }
      ]
    }
  ]
}